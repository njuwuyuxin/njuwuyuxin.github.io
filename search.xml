<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[从零实现HTTP服务器——Minihttpd（三）——使用epoll实现高并发]]></title>
    <url>%2F2020%2F06%2F29%2F%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0HTTP%E6%9C%8D%E5%8A%A1%E5%99%A8%E2%80%94%E2%80%94Minihttpd%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94%E4%BD%BF%E7%94%A8epoll%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%B9%B6%E5%8F%91%2F</url>
    <content type="text"><![CDATA[在实现了基本的接受请求，返回响应这一基本功能后，我们尝试提高该服务器能同时处理的并发请求数，实现面对海量请求时的高并发处理，主要使用了linux下的epoll机制。本文主要对epoll的基本原理进行讲解，同时展示epoll简单的使用方法。 epolllinux下的多路复用IO接口主要有select、poll和epoll，其中epoll是对select和poll的改进。所谓多路复用IO接口，就是当需要处理大批量文件描述符时使用的系统接口。文件、管道IO、socket等均使用了文件描述符，而epoll因为在处理大批量文件描述符时的高效性而收到了广泛的应用。 epoll高效的原因传统的select、poll方式，通过维护一个文件描述符数组，将所有的文件描述符统一管理，而在某一时刻，某一文件描述符可能有多种状态：缓冲区有内容可读、缓冲区有内容可写、空闲等等情况。而传统方式每次返回所有文件描述符，对所有描述符进行轮询处理，判断哪些描述符被“激活”需要进行处理。显然，使用轮询的方式，其算法复杂度为O(n)级别，也就是说随着文件描述符的增长，其耗时也为线性增长，这就导致其难以处理高并发请求的情况（海量文件描述符），因此select方式限制了文件描述符的最大数量为1024. 而epoll最大的特点是通过epoll_wait函数，每次返回的是已就绪的文件描述符列表，而所有空闲的文件描述符并不进行返回。这首先避免了大量文件描述符从内核态拷贝到用户态内存的开销，同时避免了轮询请求大量无用的判断，其算法复杂度为O(1)级别。 epoll的实现方式 epoll能够“选择性”的返回就绪态的文件描述符，主要依赖于其底层的数据结构。epoll使用了一个红黑树维护所有文件描述符的集合，这为查询，插入，删除某一描述符提供了很大便利。 另外epoll使用了一个双向链表用于维护当前所有就绪态的文件描述符，每次调用epoll_wait函数时，就是将该双向链表中的文件描述符返回。 同时epoll使用了回调机制，在把文件描述符加入到epoll红黑树中的同时，注册了相应的一些事件（如收到消息），当某一描述符的事件被触发，则将该描述符加入至双向链表中。通过这样的数据结构，使得epoll每次不必返回所有的文件描述符，降低了算法复杂度的同时节约了大量系统资源，在并发请求数线性增长的情况下，其复杂度并不会线性增加，从而轻松实现百万级别的高并发处理。 epoll机制的详细解读可以参考这篇博客:https://blog.csdn.net/daaikuaichuan/article/details/83862311 使用案例在本文实现的http服务器中，我们尝试使用epoll修改底层处理逻辑，主要修改了 server类下的start_listen函数。 epoll的核心api主要有三个 int epoll_create(int size)用于初始化epoll描述符，参数为epoll事件列表最大值（在linux内核2.6版本之后已弃用，可以忽略） int epoll_ctl(int epfd， int op， int fd， struct epoll_event *event)用于将某一描述符注册到epoll内核事件表中 int epoll_wait(int epfd， struct epoll_event *events， int maxevents， int timeout)用于获取当前就绪的文件描述符 对于这三个api的详细内容可以参考下面这篇博客：https://www.jianshu.com/p/31cdfd6f5a48 需要注意的是，epoll支持LT、ET两种模式 LT 水平触发，即当某一描述符就绪时，每次epoll_wait均会将其返回 ET 边缘触发，即当某一描述符由空闲转换为就绪时，epoll_wait将其返回一次，之后无视 这两种模式类似数字信号中电平的高低，LT模式类似高电平时持续触发，而ET模式则在低电平转换成高电平这一“边缘”时触发一次。其区别主要是LT模式可以不一次性将描述符缓冲区读完，下次epoll_wait仍然会将其返回可以继续读取。而MT模式则必须一次性将缓冲区内容读完，否则即使仍有内容未读，epoll_wait也不会返回该描述符，造成内容丢失。epoll默认使用LT模式 demo1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859void HttpServer::add_epoll_fd(int event_fd)&#123; epoll_event event; event.data.fd &#x3D; event_fd; event.events &#x3D; EPOLLIN | EPOLLET | EPOLLRDHUP; epoll_ctl(epollfd, EPOLL_CTL_ADD, event_fd, &amp;event);&#125;void HttpServer::start_listen()&#123; stringstream ss; string s_port; ss&lt;&lt;port; ss&gt;&gt;s_port; Log::log(&quot;Minihttpd running on port &quot;+s_port,INFO); epollfd &#x3D; epoll_create(5); add_epoll_fd(server_sock); &#x2F;&#x2F;把监听socket加入内核事件表 epoll_event events[MAX_EVENT_NUMBER]; while(1)&#123; int number &#x3D; epoll_wait(epollfd, events, MAX_EVENT_NUMBER, -1); stringstream s; string s_number; s&lt;&lt;number; s&gt;&gt;s_number; Log::log(&quot;current tcp links&#x3D;&quot;+s_number,DEBUG); for (int i &#x3D; 0; i &lt; number; i++)&#123; int sockfd &#x3D; events[i].data.fd; &#x2F;&#x2F;处理新到的客户连接 if (sockfd &#x3D;&#x3D; server_sock)&#123; int client_sock &#x3D; -1; struct sockaddr_in client_name; socklen_t client_name_len &#x3D; sizeof(client_name); client_sock &#x3D; accept(server_sock, (struct sockaddr *)&amp;client_name, &amp;client_name_len); if (client_sock &#x3D;&#x3D; -1)&#123; Log::log(&quot;accept failed&quot;,ERROR); continue; &#125; add_epoll_fd(client_sock); &#x2F;&#x2F;把客户端socket加入内核事件表 &#125; else if (events[i].events &amp; (EPOLLRDHUP | EPOLLHUP | EPOLLERR))&#123; Log::log(&quot;epoll end&quot;,DEBUG); &#x2F;&#x2F;服务器端关闭连接 &#125; &#x2F;&#x2F;处理客户连接上接收到的数据 else if (events[i].events &amp; EPOLLIN)&#123; thread accept_thread(accept_request,sockfd,this); accept_thread.detach(); &#125; else if (events[i].events &amp; EPOLLOUT)&#123; Log::log(&quot;epoll out&quot;,DEBUG); &#125; &#125; &#125; close(server_sock);&#125; 其中epoll_event结构体结构为 1234567891011typedef union epoll_data &#123; void *ptr; &#x2F;* 指向用户自定义数据 *&#x2F; int fd; &#x2F;* 注册的文件描述符 *&#x2F; uint32_t u32; &#x2F;* 32-bit integer *&#x2F; uint64_t u64; &#x2F;* 64-bit integer *&#x2F;&#125; epoll_data_t;struct epoll_event &#123; uint32_t events; &#x2F;* 描述epoll事件 *&#x2F; epoll_data_t data; &#x2F;* 见上面的结构体 *&#x2F;&#125;; Githubhttps://github.com/njuwuyuxin/MiniHttpd]]></content>
      <categories>
        <category>从零开始</category>
      </categories>
      <tags>
        <tag>后端</tag>
        <tag>http</tag>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零实现HTTP服务器——Minihttpd（二）]]></title>
    <url>%2F2020%2F06%2F28%2F%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0HTTP%E6%9C%8D%E5%8A%A1%E5%99%A8%E2%80%94%E2%80%94Minihttpd%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[上一篇中我们实现了接受浏览器的请求，并返回本地的网页给浏览器展示，接下来对该简单的功能进行下一步完善 Content-Typehttp响应头中非常重要的一个字段是Content-Type，它决定了浏览器如何解析返回的响应内容，如果该字段缺失则默认为text/html格式，因此我们上文返回的简单html网页并没有添加该字段，浏览器也能正常解析。但是稍微复杂的前端页面都包含了css样式文件，JavaScript脚本文件等，如果不指定Content-Type字段，则浏览器无法正确解析这些文件（有些浏览器超强的兼容性可以一定程度上自动判断内容格式）因此我们在返回本地的文件作为响应时，需要手动设置Content-Type字段，判断依据为文件的扩展名，这里使用了一个map维护扩展名与Content-Type映射关系。 12345678910111213141516171819202122232425262728293031void HttpResponse::init_content_type_map()&#123; content_type_map.insert(pair&lt;string,string&gt;(&quot;html&quot;,&quot;text&#x2F;html&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;htm&quot;,&quot;text&#x2F;html&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;shtml&quot;,&quot;text&#x2F;html&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;css&quot;,&quot;text&#x2F;css&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;js&quot;,&quot;text&#x2F;javascript&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;txt&quot;,&quot;text&#x2F;plain&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;js&quot;,&quot;text&#x2F;javascript&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;xml&quot;,&quot;text&#x2F;xml&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;ico&quot;,&quot;image&#x2F;x-icon&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;jpg&quot;,&quot;image&#x2F;jpeg&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;jpeg&quot;,&quot;image&#x2F;jpeg&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;jpe&quot;,&quot;image&#x2F;jpeg&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;gif&quot;,&quot;image&#x2F;gif&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;png&quot;,&quot;image&#x2F;png&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;tiff&quot;,&quot;image&#x2F;tiff&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;tif&quot;,&quot;image&#x2F;tiff&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;rgb&quot;,&quot;image&#x2F;x-rgb&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;mpeg&quot;,&quot;video&#x2F;mpeg&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;mpg&quot;,&quot;video&#x2F;mpeg&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;mpe&quot;,&quot;video&#x2F;mpeg&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;qt&quot;,&quot;video&#x2F;quicktime&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;mov&quot;,&quot;video&#x2F;quicktime&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;avi&quot;,&quot;video&#x2F;x-msvideo&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;movie&quot;,&quot;video&#x2F;x-sgi-movie&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;woff&quot;,&quot;application&#x2F;font-woff&quot;)); content_type_map.insert(pair&lt;string,string&gt;(&quot;ttf&quot;,&quot;application&#x2F;octet-stream&quot;));&#125; 这里添加了一些常用格式的Content-Type类型，后续涉及到更复杂的文件类型时对其进一步扩展 gzip压缩在http响应的结构中，我们常常可以看到一个名为Content-Encoding的字段，其值大多为gzip,deflate等。该字段决定的是http响应体的编码格式。目前主流浏览器均支持gzip等格式的压缩格式。使用压缩格式的最大好处就是减少网络传输的信息量，提高网页加载速度，但由于服务端多了压缩的步骤，也一定程度增加了服务器的负担（客户端单次处理时，解压的影响可以忽略不计）。而gzip格式又是应用最广泛的一种压缩格式，其对文本内容的压缩率常常可以达到40%以上，对于html,css,javascript文件均有着非常好的压缩效果。 本文实现的Minihttpd为了增加gzip格式的压缩功能使用了zlib库，其代码均为c编写，使用方法相对简单，这里列出部分供参考 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&#x2F;&#x2F;raw_data为原始数据，buffer为压缩后数据存储缓冲区，buffer_size为缓冲区大小，返回值为压缩后数据字节数uLong gzip_compress(string raw_data,Bytef*&amp; buffer,int buffer_size)&#123; size_t raw_data_size &#x3D; raw_data.size(); z_stream strm; z_stream d_stream; d_stream.zalloc &#x3D; NULL; d_stream.zfree &#x3D; NULL; d_stream.opaque &#x3D; NULL; d_stream.next_in &#x3D; (Bytef*)raw_data.c_str(); d_stream.avail_in &#x3D; raw_data_size; d_stream.next_out &#x3D; buffer; d_stream.avail_out &#x3D; buffer_size; int ret &#x3D; deflateInit2(&amp;d_stream, Z_DEFAULT_COMPRESSION, Z_DEFLATED, MAX_WBITS + 16, 8, Z_DEFAULT_STRATEGY); if (Z_OK !&#x3D; ret) &#123; Log::log(&quot;init deflate error&quot;,ERROR); &#x2F;&#x2F; cout&lt;&lt; ret &lt;&lt;endl; &#125; int err &#x3D; 0; int flag &#x3D; 0; for(;;) &#123; if((err &#x3D; deflate(&amp;d_stream, Z_FINISH)) &#x3D;&#x3D; Z_STREAM_END) break; if(flag &gt; 3)&#123; stringstream ss; ss&lt;&lt; &quot;deflate failed,errNo &#x3D; &quot;&lt;&lt;err; Log::log(ss.str(),ERROR); return 0; &#125; &#x2F;&#x2F;输出缓冲区不足，尝试扩容，最多三次扩容失败则放弃压缩 if(err &#x3D;&#x3D; Z_BUF_ERROR)&#123; flag++; delete buffer; buffer_size &#x3D; buffer_size*1.5; buffer &#x3D; new Bytef[buffer_size]; d_stream.next_out &#x3D; buffer; d_stream.avail_out &#x3D; buffer_size; stringstream ss; ss&lt;&lt; &quot;deflate buffer error,try larger buffer :&quot;&lt;&lt;flag; Log::log(ss.str(),WARN); &#125; &#125; if(deflateEnd(&amp;d_stream) !&#x3D; Z_OK)&#123; Log::log(&quot;deflate failed when end&quot;,ERROR); return 0; &#125; return d_stream.total_out;&#125; 主要工作流程为： deflateInit2() 设置压缩格式等信息 deflate() 进行压缩 deflateEnd() 压缩完毕释放临时空间等收尾工作 编码格式判别接收到http请求后，首先判断请求头中是否包含Accept-Encoding字段，如果存在，检查其后面接受的压缩格式等，决定是否使用gzip压缩（注意响应头也需要添加Content-Encoding:gzip字段） ####Githubhttps://github.com/njuwuyuxin/MiniHttpd欢迎共同学习]]></content>
      <categories>
        <category>从零开始</category>
      </categories>
      <tags>
        <tag>后端</tag>
        <tag>http</tag>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[libiconv 未定义的引用解决]]></title>
    <url>%2F2020%2F06%2F25%2Flibiconv%E6%9C%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E5%BC%95%E7%94%A8%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[最近在安装libconfig库时，编译期间出现找不到libiconv库的问题/usr/local/lib/../lib64/libstdc++.so: undefined reference to &quot;libiconv&quot;在仔细检查重新安装了libiconv库之后，问题依然无法解决。因此根据make时的记录进行追溯，发现链接错误出现在/example/c++样例编译期间 123456789make[3]: 离开目录“&#x2F;home&#x2F;downloads&#x2F;libconfig-1.7.2&#x2F;examples&#x2F;c”Making all in c++make[3]: 进入目录“&#x2F;home&#x2F;downloads&#x2F;libconfig-1.7.2&#x2F;examples&#x2F;c++” CXX example1.o CXXLD example1&#x2F;usr&#x2F;local&#x2F;lib&#x2F;..&#x2F;lib64&#x2F;libstdc++.so: undefined reference to &#96;libiconv&#39;&#x2F;usr&#x2F;local&#x2F;lib&#x2F;..&#x2F;lib64&#x2F;libstdc++.so: undefined reference to &#96;libiconv_close&#39;&#x2F;usr&#x2F;local&#x2F;lib&#x2F;..&#x2F;lib64&#x2F;libstdc++.so: undefined reference to &#96;libiconv_open&#39;collect2: error: ld returned 1 exit status 手动去查看/example/c++/下的Makefile文件时发现 1234LIBOBJS &#x3D;LIBS &#x3D; LIBTOOL &#x3D; $(SHELL) $(top_builddir)&#x2F;libtoolLIPO &#x3D; 其中LIBS变量存放编译时所需引用的外部库，而这里默认置空，我的环境使用的是CentOS7，而这里需要手动添加libiconv库的引用，因此将其改为 1234LIBOBJS &#x3D;LIBS &#x3D; -liconvLIBTOOL &#x3D; $(SHELL) $(top_builddir)&#x2F;libtoolLIPO &#x3D; 手动指定链接libiconv库。之后重新执行make，成功编译并链接。 后记类似库找不到定义的问题原因可能有很多，但大致都可以按照一下思路进行解决 首先判断库是否确实未安装（最简单的情况，安装该库即可） 如果该库已安装，查看其所在位置是否加入到系统搜索范围内 如果以上均无问题，可能需要检查Makefile或其他编译选项，尝试手动链接该动态链接库]]></content>
      <categories>
        <category>踩坑整理</category>
      </categories>
      <tags>
        <tag>Makefile</tag>
        <tag>常见问题</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CMake基础使用整理]]></title>
    <url>%2F2020%2F06%2F24%2FCMake%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[CMake是一个跨平台的编译工具，可以一次编写，在不同平台自动生成对应的Makefile文件，减少了手写Makefile以及适配不同平台时的耗时。 前言之前大部分时候在windows端使用VS开发，因此对Makefile、CMake等工具接触较少。最近尝试从头实现一个简单的HTTP服务器，主要开发环境在Linux，因此借此契机熟悉一下CMake等构建工具的使用。 目录结构目前项目文件较少，使用了较简单的目录结构 12345678910111213141516┣━ src┃ ┣━ CMakeLists.txt┃ ┣━ HttpRequest.cpp┃ ┣━ HttpResponse.cpp┃ ┣━ HttpServer.cpp┃ ...┣━ include┃ ┣━ HttpRequest.h┃ ┣━ HttpResponse.h┃ ┣━ HttpServer.h┃ ...┣━ cmake-build-debug┃ ┣━...┃ ┗━...┣━ main.cpp┣━ CMakeLists.txt 可以看到源文件和头文件分别存储在对应目录中，根目录下以main.cpp作为程序入口，最终构建目标及中间文件存放在cmake-build-debug这一独立文件夹中。 CMakeLists编写为了使上述目录结构能够正确编译链接，我们需要编写CMakeLists.txt，同时CMake能够一定程度上减少多文件多目录时来回链接顺序等头疼的问题。在这个项目里，根目录下和src目录下各有一个CMakeLists.txt文件，这也是CMake的特点，可以将Makefile拆分，每个目录各自进行编译，最终链接起来。 根目录下的CMakeLists.txt内容如下 1234567891011121314151617cmake_minimum_required (VERSION 2.6)add_definitions(-std&#x3D;c++11)set(CMAKE_CXX_FLAGS &quot;$&#123;CMAKE_CXX_FLAGS&#125; -std&#x3D;c++11 -g -Wall -Wno-unused-variable -pthread&quot;)project (Minihttpd)include_directories(include)add_subdirectory(src)# 顺序不可修改，先link_directories 再 add_executable 最后 target_link_librarieslink_directories(&#x2F;usr&#x2F;local&#x2F;lib)add_executable(Minihttpd main.cpp)target_link_libraries(Minihttpd src)target_link_libraries(Minihttpd -lconfig++) 接下来对每条语句进行简单的解释 add_definations 指令可以用来手动设置某些宏的开闭，控制编译选项，这里主要是标注使用c++11标准 set指令能够用前面的变量替代后面的字符串，这里实际上是对预定义的CMAKE_CXX_FLAGS变量进行了一个修改，来设置某些选项，主要链接pthread库使用多线程 project指令用来设置项目名（包括版本、所用语言等信息，这里缺省） include_directories指令用来指定寻找头文件的路径，这里把include目录加入到头文件搜索范围内，使得项目内文件可以找到对应头文件 add_subdirectory指令用来把子目录加入到构建列表中，最终构建结果存放在src变量中 之后的几行是在项目需要引用其他动态链接库，非常需要注意的地方 add_executable指令用来指定项目最终构建的目标文件，以及所需要的所有源文件。可以看到这里只有main.cpp，为什么没有包含src目录下其他源文件？这里其实在下面使用 target_link_libraries 指令，以动态链接库的形式引入进来。其顺序是在子目录中首先进行了部分构建，在src目录下生成了相应的libsrc.a文件，最终链接到程序入口文件上，实现了构建。 link_directories和target_link_libraries指令用来引入外部的动态链接库。其中 link_directories用来指定该动态链接库所在目录 target_link_libraries用来把所需的动态链接库引入到该项目中 这里非常需要注意的是几条语句的顺序，一定是 link_directories 把动态链接库所在目录加入寻找列表中 add_executable 指定最终构建目标名称 target_link_libraries 把需要的动态链接库加入到项目中 这里的顺序错误将导致链接失败，出现找不到动态链接库等各种问题（踩过的坑，心酸的泪） 子目录下的CMakeLists.txt内容如下 12aux_source_directory(. srcs)add_library(src $&#123;srcs&#125;) 这里的内容就非常简单 aux_source_directory指令把当前目录下所有源文件加入到srcs变量中存储 add_library使用srcs变量中所有源文件进行构建，结果输出为src。不同于add_executable，add_library的构建的最终目标为动态链接库文件，而add_executable的构建结果为一个可执行文件。这里构建成动态链接库文件也是为了在根目录下构建时进行链接 扩展在理解了多目录下CMakeLists的编写后，如果需要把源文件存放在多个不同目录中，也可以以动态链接库的形式分别进行构建、链接。而对于多级目录，也可以依次逐级构建并链接。 对于需要引用的外部动态链接库，也可以通过link_directories和target_link_libraries指令的配合进行引入。 同时本项目内使用了ninja作为构建工具，更方便了项目的构建，主要使用方法为 123cd cmake-build-debugcmake -G Ninja .. &#x2F;&#x2F;cmake支持根据CMakeLists.txt自动化生成ninja构建所需要的ninja.build等文件ninja &#x2F;&#x2F;在该目录下构建]]></content>
      <categories>
        <category>工具学习</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>CMake</tag>
        <tag>构建工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零实现HTTP服务器——Minihttpd（一）]]></title>
    <url>%2F2020%2F06%2F23%2F%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0HTTP%E6%9C%8D%E5%8A%A1%E5%99%A8%E2%80%94%E2%80%94Minihttpd%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[前言最近学习了一下Tinyhttpd的源码，对http服务器的基本工作原理有了简单的理解，而Tinyhttpd一方面年头较为久远（上个世纪的代码），另一方面基本全部由C语言实现，因此便萌生了用C++从头造轮子的想法，同时加深对TCP、HTTP等协议，socket编程等理解。 HTTP服务器基本工作流程一个最简单的HTTP服务器，其基本功能主要是接受来自浏览器的http请求，之后根据请求内容返回相应的http response。因此对于我们要实现的最基本的http服务器，首先要完成的就是接受请求和发送响应。 HTTP报文格式HTTP请求HTTP请求主要由请求头（header）和请求体（body）构成，中间使用了空行（\r\n）进行分隔，具体结构如图所示以浏览器访问某一网站为例，在除去最开始的 “请求方法 URL 协议版本” 这一行后，剩余部分均为请求头部字段，没有列出的首行格式形如 GET /index.html http/1.1 HTTP响应HTTP响应结构与请求类似，分为响应头和和响应体，中间以空行分隔。响应头首行为 “协议版本 HTTP状态码“（OK可省略），剩余均为头部字段，按需求可自行添加。 基本的HTTP服务器实现在理解了http服务器的简单工作流程和http请求相关格式后，我们便可以动手编写最基础的http服务器。为了方便各模块抽象，目前主要使用三个类进行基础维护，分别为：HttpServer、HttpRequest、HttpResponse HttpRequest和HttpResponse这两个类主要是便于进行http请求的解析与响应报文的构造，也可以方便的看出http请求和响应的简单结构。HttpRequest结构如下，分别对应了请求报文格式，可以方便的读取头部各字段信息 123456789101112class HttpRequest&#123;public: HttpRequest(string raw_data); inline const string get_method()&#123; return method; &#125;; inline const string get_url()&#123; return url; &#125;; inline const map&lt;string,string&gt;&amp; get_header()&#123; return header; &#125;;private: string method; &#x2F;&#x2F;该http请求方法 string url; &#x2F;&#x2F;请求URL string version; &#x2F;&#x2F;http版本 map&lt;string,string&gt; header;&#125;; HttpResponse结构如下，对于通用字段单独列出方便快速设置，同时提供自定义字段设置方法，而load_from_file则提供了文件读取相关功能，主要对应于解析请求中的url字段，找到服务器上相应文件进行返回。 12345678910111213141516171819202122232425262728class HttpResponse&#123;public: HttpResponse(int st); void set_header(string key, string val); &#x2F;&#x2F;设置头部自定义字段 void load_from_file(string url); string get_response(); &#x2F;* 基础头部字段，供快速填充，自定义字段需手动设置 *&#x2F; string Allow; string Content_Encoding; string Content_Length; string Content_Type; string Expires; string Last_Modified; string Location; string Refresh; string Set_Cookie; string WWW_Authenticate; private: string version; &#x2F;&#x2F;http版本 string status; &#x2F;&#x2F;http状态码 string date; &#x2F;&#x2F;response生成时间 string server; &#x2F;&#x2F;http服务器名称 map&lt;string,string&gt; custom_header; &#x2F;&#x2F;自定义头部字段 string generate_header(); &#x2F;&#x2F;使用全部信息组装HTTP Response头部 string response_body; &#x2F;&#x2F;返回内容体&#125;; HttpServerHttpServer类主要用于维护单个服务器实例，也是服务器的最核心功能。目前的基本功能便是建立套接字，接受请求并返回，其类结构为 1234567891011121314class HttpServer&#123;public: HttpServer(); HttpServer(u_short p); inline int get_sock_id()&#123; return server_sock; &#125;; inline u_short get_port()&#123; return port; &#125;; void start_listen(); static void accept_request(int client_sock,HttpServer* t);private: int server_sock; u_short port; string baseURL; void startup();&#125;; 其中startup函数用于创建套接字用于之后监听请求，HTTP协议基于的是TCP协议，因此套接字需正确设置，配置端口号、本地网卡IP等信息，这里为了便于使用，如果不指定端口号会随机使用某一可用端口。 123456789101112131415161718192021222324252627int on &#x3D; 1; struct sockaddr_in name; server_sock &#x3D; socket(PF_INET, SOCK_STREAM, 0); &#x2F;&#x2F;使用TCP协议 if (server_sock &#x3D;&#x3D; -1) cerr&lt;&lt;&quot;[ERROR]: create socket failed&quot;&lt;&lt;endl; memset(&amp;name, 0, sizeof(name)); name.sin_family &#x3D; AF_INET; name.sin_port &#x3D; htons(port); name.sin_addr.s_addr &#x3D; htonl(INADDR_ANY); if ((setsockopt(server_sock, SOL_SOCKET, SO_REUSEADDR, &amp;on, sizeof(on))) &lt; 0) &#123; cerr&lt;&lt; &quot;[ERROR]: setsockopt failed&quot;&lt;&lt;endl; &#125; if (bind(server_sock, (struct sockaddr *)&amp;name, sizeof(name)) &lt; 0) cerr&lt;&lt;&quot;[ERROR]: bind failed&quot;&lt;&lt;endl; if (port &#x3D;&#x3D; 0) &#x2F;* if dynamically allocating a port *&#x2F; &#123; socklen_t namelen &#x3D; sizeof(name); if (getsockname(server_sock, (struct sockaddr *)&amp;name, &amp;namelen) &#x3D;&#x3D; -1) cerr&lt;&lt;&quot;[ERROR]: getsockname failed&quot;&lt;&lt;endl; port &#x3D; ntohs(name.sin_port); &#125; &#x2F;&#x2F;listen第二个参数为连接请求队列长度，5代表最多同时接受5个连接请求 if (listen(server_sock, 5) &lt; 0) cerr&lt;&lt;&quot;[ERROR]: listen failed&quot;&lt;&lt;endl; 在创建了socket后，我们便可使用该socket监听发来的tcp数据包，从中识别出http请求，这部分工作交由start_listen()函数完成 1234567891011121314151617181920cout&lt;&lt;&quot;httpd running on port &quot;&lt;&lt;port&lt;&lt;endl; int client_sock &#x3D; -1; struct sockaddr_in client_name; socklen_t client_name_len &#x3D; sizeof(client_name); pthread_t newthread; while (1) &#123; &#x2F;&#x2F;accept函数用来保存请求客户端的地址相关信息 client_sock &#x3D; accept(server_sock, (struct sockaddr *)&amp;client_name, &amp;client_name_len); if (client_sock &#x3D;&#x3D; -1) cerr&lt;&lt;&quot;[ERROR]: accept failed&quot;&lt;&lt;endl; thread accept_thread(accept_request,client_sock,this); accept_thread.join(); &#125; close(server_sock); 这里主要使用accept函数保存客户端socket相关信息，在接收到客户端发送的一条请求后，创建一个新的线程用于该请求的处理，具体处理部分如下，主要通过read读取原始数据存入buffer，将该信息交给HttpRequest类进行简单解析，同时利用HttpResponse类构造响应报文，使用send将该响应发送回客户端，之后关闭该套接字。 123456789101112131415161718int client &#x3D; client_sock; char buf[1024]; read(client_sock,(void*)buf,1024); string req(buf); HttpRequest request(req); cout&lt;&lt;&quot;url: &quot;&lt;&lt;request.get_url()&lt;&lt;endl; string req_url &#x3D; t-&gt;baseURL + request.get_url(); auto header &#x3D; request.get_header(); cout&lt;&lt;&quot;[GET REQUEST]: Host &#x3D; &quot;&lt;&lt;header.find(&quot;Host&quot;)-&gt;second&lt;&lt;endl; HttpResponse response(200); response.load_from_file(req_url); response.Content_Type &#x3D; &quot;text&#x2F;html&quot;; string res_string &#x3D; response.get_response(); &#x2F;&#x2F; cout&lt;&lt;res_string&lt;&lt;endl; send(client,res_string.c_str(),strlen(res_string.c_str()),0); close(client); 至此一条http请求便可以被正确解析并返回，总体流程为： 创建server_socket 监听某一端口请求 接收数据解析请求 构造响应报文 发送响应，关闭客户端套接字 到这里一个具备基础功能的http服务器已经初具雏形，可以解析简单的http请求，同时根据请求路径读取本地的html文档进行返回，交由浏览器展示。之后我们会不断完善该服务器，实现更复杂的一些功能。 Github地址：https://github.com/njuwuyuxin/MiniHttpd]]></content>
      <categories>
        <category>从零开始</category>
      </categories>
      <tags>
        <tag>后端</tag>
        <tag>http</tag>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《UnityShader入门精要》学习笔记（三）——UnityShader初探]]></title>
    <url>%2F2020%2F05%2F26%2F%E3%80%8AUnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94UnityShader%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[何为Unity Shader在传统的开发模式中，开发者如果想要设置自定义的渲染模式，需要和大量文件和设置打交道（包括编写顶点着色器、片元着色器、选择图形API、加载资源到GPU等等），非常繁琐复杂。Unity Shader就是在此之上的更高级的一层封装，开发者只需要在Shader Lab中编写Unity Shader文件，即可交由Unity引擎实现自定义渲染效果。因此Unity Shader与传统的Shader有所不同，它定义的是要显示一个材质的所有东西，而不仅仅是着色器代码。 而在使用Unity Shader时，我们首先需要创建一个材质，将编写的Unity Shader文件挂载到该材质上，之后再为各个物体应用该材质。由此可以看出，Unity Shader是与材质牢牢绑定的。 Unity Shader文件基本结构一个UnityShader的基本文件结构大致如下 123456789101112Shader &quot;ShaderName&quot;&#123; Properties&#123; &#x2F;&#x2F;相关属性 &#125; SubShader&#123; &#x2F;&#x2F;显卡A使用的子着色器 &#125; SubShader&#123; &#x2F;&#x2F;显卡B使用的子着色器 &#125; Fallback &quot;VertexLit&quot;&#125; 一个完整的Unity Shader包括shader名 ShaderName、shader包含的属性Properties、使用的子着色器SubShader、以及无法调用任何子着色器时执行的Fallback PropertiesProperties定义了一系列属性，这些属性将会出现在材质面板中，Properties语句块的定义如下： 1234Properties&#123; Name(&quot;display name&quot;,PropertyType) &#x3D; DefaultValue Name(&quot;display name&quot;,PropertyType) &#x3D; DefaultValue&#125; Name为属性名，可以在后续代码中使用，一般以下划线开头 display name指的是在材质面板中显示的名称 PropertyType为属性类型 DefaultValue为属性的默认值，第一次为某个材质应用该Shader时就会使用该默认值 在properties声明变量后，我们还需要在cg代码中定义变量来进行使用。需要注意的是，即使我们不在properties中声明变量，我们也可以通过脚本的方式向shader传递变量的值，因此properties块的功能仅仅是为了让对应属性出现在材质面板中。 SubShaderSubShader主要包含这样几个部分 1234567SubShader&#123; [Tags] [RenderSetup] Pass&#123; ... &#125;&#125; 其中 标签是一系列“键值对”，用来进行和渲染引擎的“沟通”，告知其应该怎样、何时渲染这个对象 渲染设置是用来设置显卡渲染时的一些选项，如是否开启混合等 Pass是最重要的语句块，可以有多个，每个Pass在渲染流程中执行一次，但是为了避免多个pass造成性能下降，我们应该尽可能用最少的Pass实现渲染功能。 对于每个Pass，结构类似SubShader 123456Pass&#123; [name] [Tags] [RenderSetup] ...&#125; 名称：可以设置Pass的名称，这样我们在其他SubShader中，可以通过UsePass来使用其他Shader中定义的Pass，实现代码复用（需要指明路径）。注意，Unity会自动将Pass的名称转换为全大写字母 标签：其中Pass可以使用的标签和SubShader略有不同 渲染设置：和SubShader一致。如果我们在SubShader中进行设置，则会应用于所有Pass。如果不想这样，可以分别为每个Pass设置不同的RenderSetup 一个UnityShader文件中可以包含多个SubShader，主要用来实现不同显卡上的兼容性，如果第一个SubShader中的某些指令显卡不支持，则会使用下面的SubShader，以此类推。如果没有一个SubShader兼容，则会使用Fallback FallbackFallback可以认为是所有SubShader都无法使用时最迫不得已的选项，是最基础的渲染。当然也可以手动关闭，意味着如果没有SubShader支持，我们就不去管他。]]></content>
      <categories>
        <category>UnityShader学习笔记</category>
      </categories>
      <tags>
        <tag>Unity</tag>
        <tag>Shader</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Unity Shader 入门精要》学习笔记（二）—— GPU流水线]]></title>
    <url>%2F2020%2F05%2F07%2F%E3%80%8AUnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94GPU%E6%B5%81%E6%B0%B4%E7%BA%BF%2F</url>
    <content type="text"><![CDATA[GPU流水线GPU流水线的大致流程和步骤如下图所示其中深灰色的步骤为可编程的，浅色步骤不可编程但可配置，灰色步骤不可编程也不可配置。下面简单介绍每个步骤的基本任务。 几何阶段顶点着色器顶点着色器步骤的功能仅仅是对上一阶段CPU输出的顶点信息进行坐标变换以及计算顶点颜色光照等。这里的各顶点信息都是完全独立的，并且无法获取顶点之间的关系，因此可以被GPU并行计算，效率较高。 这里的坐标变换指的是：从模型空间坐标变换到齐次剪裁坐标（均为三维空间） 曲面细分着色器一个可选的着色器，用于细分图元。 几何着色器一个可选的着色器，用于逐图元进行着色。 裁剪一个非常重要的步骤，用于将每个图元在摄像机视野外的部分裁剪掉。完全不在视野内的图元会直接被舍弃掉不传递给下一阶段，完全在视野内的图元会直接传递给下一阶段。因此裁剪主要针对一部分在摄像机视野内，另一部分在视野外的图元。 屏幕映射屏幕映射阶段主要工作为：将之前得到的顶点的坐标映射到屏幕坐标系中，即完成从三维空间向二维平面的投影。注意：OpenGL和DirectX的屏幕坐标有所差异，OpenGL的原点在左下角，DirectX的原点在左上角。 光栅化阶段三角形设置在几何阶段，我们得到了一系列在屏幕坐标系中的顶点坐标。而一个三角形由三个顶点组成，因此我们需要通过这些顶点坐标，计算出每个三角形图元具体覆盖了哪些像素，这个过程就叫做 三角形设置。三角形设置就是计算每个三角形边界的表示方式，为下一阶段做准备。 三角形遍历在得到了一系列三角形网格的表示数据后，我们需要判断屏幕上的每个像素，是否被某一个三角形网格所覆盖，因此对于每个像素都需要对所有三角形网格进行遍历。如果一个像素被覆盖，那么会通过插值等方式计算出他的片元信息。注意：这里的“片元”并不等同于“像素”，片元所包含的信息更加丰富（包括他的坐标、深度信息、顶点信息等等），这些信息用来最终生成一个像素的颜色。三角形遍历阶段的最终输出就是一个片元序列，用于下一阶段的片元着色器。 片元着色器我们知道片元是用来最终生成一个像素所需的前置数据结构，这个由片元生成像素的过程，就是交由片元着色器完成的。这个过程是可以高度编程的，我们所能够实现的大部分效果，也都是在这一步进行的。片元着色器的最终输出是每个片元的一个或多个颜色值。在这里仍然没有得到最终的像素，但已经得到了每个片元的颜色信息，在下一步中，我们会得到每个像素的最终颜色值。 逐片元操作逐片元操作的工作主要有两个： 可见性测试 合并 先说第一点，上面得到的片元信息中包括了每个片元的深度信息，这可以帮我们判断每个片元之间的覆盖情况，没有通过深度测试的片元意味着被其他片元所遮挡，因此会被舍弃。可见性测试不仅仅是深度测试，还包括模板测试等一系列其他测试，只有通过了可见性测试的片元才能进入接下来的合并阶段。 合并阶段相对而言容易理解，因为我们在渲染每一帧画面时遵照的顺序是依次渲染每一个三角形图元，因此为了生成一幅完整的画面，我们需要将当前渲染的三角形与之前已渲染的部分画面进行合并，最终得到一幅完整的画面。这个阶段也是可以高度配置的，我们可以指定合并的具体规则，从而实现包括透明之类的效果。 在整个阶段完成后，我们终于将片元信息转化为了每个像素的颜色值，最终生成了一幅画面。]]></content>
      <categories>
        <category>UnityShader学习笔记</category>
      </categories>
      <tags>
        <tag>Unity</tag>
        <tag>Shader</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Unity Shader 入门精要》学习笔记（一）—— 渲染流水线]]></title>
    <url>%2F2020%2F05%2F06%2F%E3%80%8AUnityShader%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[最近在掌握了一些图形学基础后，下定决心要学习一下Shader相关内容，加之平时开发一些游戏Demo基本上基于Unity实现，于是搬出来《Unity Shader 入门精要》开始研读，顺便整理一下笔记加深理解。本文主要是在每章学习后，首先凭印象整理出大致框架和重点概念，之后再参照原文进行校对勘误，如此一来加深了理解同时又能保证知识的准确性。 渲染流水线渲染流水线就是将一幅画面渲染的过程拆分为多个阶段，每个阶段执行各自功能同时可以并行计算以提高速度。由于采用了流水线模式，因此整个渲染过程的耗时基本上取决于整条流水线中速度最慢的步骤。 概念上的渲染流水线主要分为三个阶段：应用阶段、几何阶段、光栅化阶段他们只是从概念上将渲染流水线划分为三个主要步骤，实际GPU的流水线步骤会更加细化。 应用阶段应用阶段是用户可编程程度最高的步骤，通常是由CPU负责的部分。这个阶段主要任务是： 准备好场景数据（包括需要渲染的物体、摄像机角度等） 进行粗粒度的剔除（剔除被遮挡的物体，与光栅化阶段有所不同） 设置每个模型的渲染状态（包括使用的材质、纹理、shader等） 该阶段的最终输出就是渲染所需的几何信息，即渲染图元，重点是三维信息！ 几何阶段几何阶段的主要工作是将上一步的渲染图元进行逐顶点、逐边的操作。通俗来说就是决定需要绘制的图元是什么，绘制在什么位置，如何绘制等等。 这里的遮挡计算与应用阶段不同，应用阶段进行的是粗粒度的剔除，即完全被遮挡的物体会直接被剔除，以减少之后几何阶段的计算等。而几何阶段则需要计算各图元之间的部分遮挡，即一个图元哪些部分被遮挡不需绘制，哪些部分未被遮挡需要绘制。 其中最重要的一项工作就是将顶点坐标转换到屏幕空间中。该阶段通常在GPU上进行，最终输出是屏幕空间的二维顶点坐标、每个顶点的相关信息等，重点是二维信息！ 光栅化阶段光栅化阶段主要使用上一阶段提供的数据来产生屏幕上的像素。这个阶段的主要任务是决定每个渲染图元中的哪些像素需要被绘制出来，这里需要用到上阶段提供的逐顶点信息，进行插值，进行逐像素的处理。 CPU与GPU的通信通过上面我们了解到渲染流水线的开始是应用阶段，而应用阶段主要是由CPU进行，因此整个渲染过程也是由CPU发起，之后交由GPU进行处理。主要分为三个阶段： 加载数据至显存（硬盘-&gt;内存-&gt;显存） 设置渲染状态（使用的材质、纹理、shader等） 发起DrawCall，告诉GPU已经准备好渲染所需信息，可以开始工作啦 下一节主要整理关于GPU流水线的主要步骤和重点功能。]]></content>
      <categories>
        <category>UnityShader学习笔记</category>
      </categories>
      <tags>
        <tag>Unity</tag>
        <tag>Shader</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零搭建教务抢课系统（五）]]></title>
    <url>%2F2020%2F01%2F13%2F%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BA%E6%95%99%E5%8A%A1%E6%8A%A2%E8%AF%BE%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%BA%94%EF%BC%89%2F</url>
    <content type="text"><![CDATA[目录（一）核心功能：模拟登陆（二）使用Cookie进行模拟登录（三）获取教务网选课列表（四）循环选课（五）断线重连 Github链接： https://github.com/njuwuyuxin/CourseGrabber断线重连目前的抢课脚本的一个缺陷在于，当用户挂机进行自动抢课时，如果出现临时网络波动造成短时间断网，会造成抢课过程中断，程序异常退出。而我们希望对于临时的网络中断或网络波动，可以自动尝试重连，自动恢复，防止一次临时断网导致程序退出。因此这里为我们的抢课脚本加入了断线重连处理，主要思路为对requests请求失败时抛出的异常进行处理，如果发现了如连接失败或请求超时等情况，自动进行重试。代码如下： 123456789101112while True: try: selectResult &#x3D; session.post(host+&#39;student&#x2F;elective&#x2F;selectCourse.do&#39;,selectCourse_reqdata) except requests.exceptions.ConnectionError: connectionFailedFlag&#x3D;True print(&quot;连接超时，正在尝试重新连接&quot;) time.sleep(1) else: if connectionFailedFlag: connectionFailedFlag&#x3D;False print(&quot;重连成功，继续为您抢课&quot;) break 使用requests发出的post请求，当请求失败时会返回一个requests.exceptions.ConnectionError类型的异常。我们在外层使用了一个循环，如果请求成功则终止循环，如果接收到异常，则继续进行请求。 测试时首先启动抢课脚本开始抢课，期间手动断开电脑网络，一段时间后再重新连接网络，检查脚本是否能继续抢课。 测试结果如下：]]></content>
      <categories>
        <category>简单尝试</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>抢课系统</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零搭建教务抢课系统（四）]]></title>
    <url>%2F2019%2F12%2F29%2F%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BA%E6%95%99%E5%8A%A1%E6%8A%A2%E8%AF%BE%E7%B3%BB%E7%BB%9F%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[目录 （一）核心功能：模拟登陆（二）使用Cookie进行模拟登录（三）获取教务网选课列表（四）循环选课（五）断线重连 Github链接： https://github.com/njuwuyuxin/CourseGrabber循环选课在成功实现了登陆系统，拉取课程列表之后，我们离成功只差最后一步，只需要模拟浏览器，向对应端口发送选课请求即可。手动在网页上选择任意一门课之后发现，选课请求体结构非常简单，同样为Post请求 1234&#123; &#39;method&#39;:&#39;addSpecialitySelect&#39;, &#39;classId&#39;:&#39;xxxx&#39;&#125; 这里的classID就是上一篇中提到的后台为每个课程标记的ID，并不是大家平时使用的课程号。好在上一篇中，我们已经对每门课的序号和课程ID进行了映射。 基本思路理清后，代码的部分就相对非常简单。 123456789101112131415161718192021222324def GrabCourse(courseID,interval&#x3D;0): while(True): selectCourse_reqdata&#x3D;&#123;&#125; selectCourse_reqdata[&#39;method&#39;]&#x3D;&quot;addSpecialitySelect&quot; selectCourse_reqdata[&#39;classId&#39;]&#x3D;str(courseID) selectResult &#x3D; s.post(host+&#39;student&#x2F;elective&#x2F;selectCourse.do&#39;,selectCourse_reqdata) soup &#x3D; BeautifulSoup(selectResult.content,&quot;html.parser&quot;,from_encoding&#x3D;&#39;utf-8&#39;) for tag in soup.find_all(&#39;div&#39;): if tag.get(&#39;id&#39;)&#x3D;&#x3D;&quot;successMsg&quot;: print(&quot;抢课成功！&quot;) return elif tag.get(&#39;id&#39;)&#x3D;&#x3D;&quot;errMsg&quot;: if tag.string.find(&quot;已经&quot;)!&#x3D;-1: print(&quot;您已经抢到该课程啦~&quot;) exit() elif tag.string.find(&quot;错误&quot;)!&#x3D;-1: print(&quot;出现错误，添加失败&quot;) exit() else: print(&quot;当前班级已满，仍在为您持续抢课&quot;) else: pass if interval!&#x3D;0: time.sleep(interval) 这里的GrabCourse函数接收两个参数，第一个就是课程ID，第二个为一个可调的时间间隔。为了避免对教务系统造成过大负担（防止被查水表），这里默认设置了每次发送选课请求的时间间隔为1秒。 同时对每次选课请求的返回进行一下检验，主要分为四种情况： 选课成功：理想情况 已经选课：证明课表这已经选中这门课 班级已满：抢课系统主要针对的正是这种情况，班级满时需要循环发送请求，等待班级空出位置的瞬间。 出现错误：多为课程ID填写错误，或者选择了其他院系专业课（没有选课权限）等情况 对每种情况分别处理即可 其他尝试由于之前拉取课程列表时，尝试通过填写其他院系编号来构造请求体，成功拉取到了其他院系的课表，可知教务系统后端对院系方面审核并不十分严格。因此在选课阶段同样进行了类似的尝试（作死），方法同样是在构造选课请求时，填写其他院系课程的课程ID结果：返回“出现错误，添加失败”（笑）可见教务平台至少在选课的时候还是稍微做了一下身份验证。不过至此，整个抢课系统的基本功能已经实现。可以成功登录、获取列表、循环发送选课请求。接下来的工作就是优化人机交互以及断线重连相关功能。]]></content>
      <categories>
        <category>简单尝试</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>抢课系统</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零搭建教务抢课系统（三）]]></title>
    <url>%2F2019%2F12%2F28%2F%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BA%E6%95%99%E5%8A%A1%E6%8A%A2%E8%AF%BE%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[目录（一）核心功能：模拟登陆（二）使用Cookie进行模拟登录（三）获取教务网选课列表（四）循环选课（五）断线重连 Github链接： https://github.com/njuwuyuxin/CourseGrabber获取选课列表在研究了教务网的js代码以及抓包分析之后，发现教务网拉取专业选课列表的接口接收不同数量的参数（有默认参数）专业选课页面的加载逻辑为，初次进入页面自动发送一条post请求，请求体为 123&#123; &#39;method&#39;:&#39;specialityCourseList&#39;&#125; 该请求只包含调用的方法名，其余均为默认参数，用来拉取默认显示的课程列表 当用户在下拉选单中手动选择某项之后，会向同一端口再次发送一条post请求，请求体为 12345&#123; &#39;method&#39;:&#39;specialityCourseList&#39;, &#39;specialityCode&#39;:&#39;221&#39;, &#39;courseGrade&#39;:&#39;2016&#125; 这次请求体中包含了所在专业的专业编号，以及对应年级 解析网页获得课程列表按照请求格式构造好请求体中，response返回的HTML文档就是包含了课程列表的页面这里使用了Beautiful Soup进行解析，可以看到课程列表是以、 标签的形式进行显示，按对应格式解析即可 123456789101112131415161718192021soup &#x3D; BeautifulSoup(courseList.content,&quot;html.parser&quot;,from_encoding&#x3D;&#39;utf-8&#39;)soup &#x3D; BeautifulSoup(courseList.content,&quot;html.parser&quot;,from_encoding&#x3D;&#39;utf-8&#39;)trs &#x3D; soup.find_all(&#39;tr&#39;,&#123;&#39;class&#39;:&#39;TABLE_TR_01&#39;&#125;)print(&quot;序号\t课程号\t\t课程名\t\t\t学分\t学时\t类型\t开课院系&quot;)for tr in trs: tds &#x3D; tr.find_all(&#39;td&#39;) courseNo &#x3D; tds[0].find(&#39;a&#39;).find(&#39;u&#39;).string if(tds[1].string.__len__()&lt;&#x3D;7): print(str(trs.index(tr)+1)+&#39;\t&#39;+courseNo+&#39;\t&#39;+tds[1].string+&#39;\t\t&#39;+tds[2].string+&#39;\t&#39;+tds[3].string+&#39;\t&#39;+tds[4].string+&#39;\t&#39;+tds[6].string) else: print(str(trs.index(tr)+1)+&#39;\t&#39;+courseNo+&#39;\t&#39;+tds[1].string+&#39;\t&#39;+tds[2].string+&#39;\t&#39;+tds[3].string+&#39;\t&#39;+tds[4].string+&#39;\t&#39;+tds[6].string) click_td &#x3D; tr.find(&#39;td&#39;,&#123;&#39;onclick&#39;:True&#125;) if click_td&#x3D;&#x3D;None: courseIdList.append(&quot;&quot;) pass else: # print(click_td[&#39;onclick&#39;]) js &#x3D; click_td[&#39;onclick&#39;] args &#x3D; js.split(&#39;,&#39;) courseID &#x3D; args[4][0:5] courseIdList.append(courseID) 由于教务网后端较为特殊，选课的请求体中课程id有单独编号需要提取，而不是使用课程编号（后文有讲），因此额外做了一些解析，HTML解析这里不具有普遍参考价值. 获取的课程列表展示如下： 参考资料Beautiful Soup4 中文文档]]></content>
      <categories>
        <category>简单尝试</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>抢课系统</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零搭建教务抢课系统（二）]]></title>
    <url>%2F2019%2F12%2F27%2F%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BA%E6%95%99%E5%8A%A1%E6%8A%A2%E8%AF%BE%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[目录（一）核心功能：模拟登陆（二）使用Cookie进行模拟登录（三）获取教务网选课列表（四）循环选课（五）断线重连 Github链接： https://github.com/njuwuyuxin/CourseGrabber使用cookie模拟登录在成功实现了基本登陆后，为了方便使用，这里尝试使用cookie进行登录 首先我们在创建session时，初始cookie为空，可以打印进行查看 12s &#x3D; requests.session()print(s.cookies.get_dict()) 在构造登陆请求体，成功登陆之后，session中的cookies被自动更新，可以打印查看，南大教务平台的Cookie形如 12345&#123; &#39;user_id&#39;:&#39;&quot;1612xxxxx 1577448172273&quot;&#39;, &#39;ARRAffinity&#39;:&#39;80372ade9da56061dc1cfb0f216b6917726c2c01e3d804e60cad7fce0e0af662&#39;, &#39;JSESSIONID&#39;:&#39;8D6204D5EDBE04DC6088DB9BE43A5924&#39;&#125; 可以看到共有三个表项，这里在成功登录之后，手动将其保存到本地文件中。这里没有使用相关库函数，而是手动实现了简单的cookie存储 1234def SaveCookie(session): with open(&quot;.cookie&quot;,&#39;w&#39;) as f: for key,val in session.cookies.get_dict().items(): f.write(key+&quot;:&quot;+val+&#39;\n&#39;) 同时实现了从文件读取cookie的方法 12345678910def GetCookie(session): cookie &#x3D; &#123;&#125; if &quot;.cookie&quot; not in os.listdir(): return cookie with open(&quot;.cookie&quot;,&#39;r&#39;) as f: for line in f: line &#x3D; line.replace(&#39;\n&#39;,&#39;&#39;).replace(&#39;\r&#39;,&#39;&#39;) item &#x3D; line.split(&#39;:&#39;) cookie[item[0]] &#x3D; item[1] return cookie cookie的保存与读取实现之后，登陆部分的逻辑可以改为： 首先检查本地是否存在cookie 如果存在cookie，尝试使用cookie登录；如果不存在，直接使用账号密码登录 如果cookie登录成功，直接进入系统；如果cookie已过期，则重新使用账号密码登录，并更新本地cookie 12345678910#获取cookie，如果本地有cookie，尝试使用cookie登录 c &#x3D; GetCookie(session) session.cookies.update(c) if c: rs &#x3D; session.get(host+&quot;student&#x2F;index.do&quot;) #教务平台首页，如果能够进入，说明已成功登录 if rs.content.__len__() &gt; 5000: print(&quot;登陆成功!&quot;) return True else: print(&quot;登录已过期，请重新登录&quot;) 这样我们基本实现了使用cookie进行登录，避免了重复输入账号密码及验证码的验证]]></content>
      <categories>
        <category>简单尝试</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>抢课系统</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零搭建教务抢课系统（一）]]></title>
    <url>%2F2019%2F12%2F26%2F%E4%BB%8E%E9%9B%B6%E6%90%AD%E5%BB%BA%E6%95%99%E5%8A%A1%E6%8A%A2%E8%AF%BE%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[目录（一）核心功能：模拟登陆（二）使用Cookie进行模拟登录（三）获取教务网选课列表（四）循环选课（五）断线重连 Github链接： https://github.com/njuwuyuxin/CourseGrabber一、前言响应群里学弟学妹号召，心血来潮想做一个南大教务网的抢课系统。在仔细研究了一下教务平台的js代码之后，发现几乎没有什么防护措施，于是便开始着手尝试起来。 抢课系统的主要思路无非就是以下几步： 模拟教务平台的网页登录，获取session 登入平台后拉取各个课程列表 找到对应课程编号，构造选课请求体，循环发送 为了方便调试检验，还使用了wireshark进行简单抓包（可省略），有需要的小伙伴可以自行下载 二、模拟登陆首先进入教务网登陆界面，尝试一次普通登录可以发现登录的请求体主要由四个表项组成，returnUrl暂无具体含义，默认为null，其余均为用户提交表单。这里唯一比较棘手的一点是验证码的获取。 验证码获取南大教务平台的验证码是通过向后端jsp请求获得。因此在代码里我们同样用模拟浏览器的方式进行请求。 123456789101112#首先创建一个sessionsession &#x3D; requests.session()#取得验证码图片now_time &#x3D; str(int(time.time()))pic_url &#x3D; host + &#39;ValidateCode.jsp&#39;pic &#x3D; session.get(pic_url).contentim &#x3D; Image.open(BytesIO(pic)) #直接打开图片 im.show()filename &#x3D; &#39;&#39; + now_time + &#39;.jpg&#39; with open(filename, &#39;wb&#39;) as f: f.write(pic) 这里首先创建了一个session，确保获取验证码和登录请求为同一个session，向对应jsp请求，将请求获得的图片保存在本地。之后尝试使用了ocr进行验证码的自动识别，由于验证码干扰严重，OCR无法识别，因而放弃 123456#尝试使用OCR自动识别验证码，但是由于验证码干扰较多，不能正确识别，因此采用手动输入方式# img &#x3D; Image.open(filename)# img&#x3D;img.convert(&#39;L&#39;)# vcode &#x3D; pytesseract.image_to_string(img) # 使用ocr技术将图片中的验证码读取出来# time.sleep(0.3) # print(vcode) OCR无法自动识别，那么我们只能采用手动输入验证码的方式，每次登陆时根据获取到本地的验证码进行输入，登陆后自动删除临时图片。同时发现验证码大约有100秒有效时间，因此需及时输入，否则验证码过期需要重新获取 登录请求体构造之后我们就可以构造登录请求体，这里为了方便测试，可以选择性读取存储用户信息的配置文件，也可以控制台进行输入 12345678910111213141516171819login_data&#x3D;&#123;&#125;files &#x3D; os.listdir()if &quot;user.cfg&quot; in files: with open(&quot;user.cfg&quot;,&#39;r&#39;) as f: for line in f: items &#x3D; line.split(&quot;:&quot;) items[1]&#x3D;items[1].replace(&#39;\n&#39;,&#39;&#39;).replace(&#39;\r&#39;,&#39;&#39;) login_data[items[0]]&#x3D;items[1]else: print(&quot;请输入用户名&quot;) login_data[&#39;userName&#39;]&#x3D;input() print(&quot;请输入密码&quot;) login_data[&#39;password&#39;]&#x3D;input() login_data[&#39;retrunURL&#39;]&#x3D;&quot;null&quot;print(&quot;请输入验证码(Please enter the ValidateCode)&quot;)vcode&#x3D;input()os.remove(filename) #输入完验证码后自动删除本地图片 login_data[&#39;ValidateCode&#39;]&#x3D;vcode 发送登录请求构造好请求体之后，我们将对应post请求发送到后端端口即可，这里由于无论登陆成功或失败，都会返回200表示请求成功，并不代表登陆成功。而返回的response分别对应错误页面的html和成功页面的html，因此这里简单对response长度进行判断来判断是否登陆成功。 12345678#发送登录请求response &#x3D; session.post(host+&quot;login.do&quot;,login_data)if response.content.__len__() &gt; 1100: print(&quot;登陆成功!&quot;) return Trueelse: print(&quot;登录失败，请检查账号密码及验证码&quot;) return False 输入完用户信息后，成功登录后，wireshark抓包可以看到对应数据包打印请求体后，可以发现正是教务平台登陆成功后的主页的html，至此，抢课系统的核心登录部分已经完成。之后可以解析HTML获得相关信息（类似爬虫），或发送选课请求等均可。]]></content>
      <categories>
        <category>简单尝试</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>抢课系统</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nodejs+express框架搭建简单后端服务]]></title>
    <url>%2F2019%2F06%2F07%2Fnodejs-express%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E7%AE%80%E5%8D%95%E5%90%8E%E7%AB%AF%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[Node安装由于后端服务通常部署在linux服务器上，因此简单说下linux环境下node的安装。 可以选择去官网下载编译好的二进制文件，软链接到环境目录下。也可以使用apt工具直接安装 1sudo apt-get install node Express框架express是一个功能十分强大的框架，可以同时兼顾前后端开发。但由于这次只是想用express实现后端服务，因此不需要express提供的前端开发模板相关功能。所以只是在项目中引入了express模块 1npm install express 之后就可以在项目中通过require的方式使用express模块 Express的使用首先需要在需要的文件中引入express模块 12var express &#x3D; require(&#39;epxress&#39;);var app &#x3D; express(); 之后需要创建一个http服务器，但是由于我的网站而言，需要提供https服务，因此创建了一个https服务器 1234var httpsServer &#x3D; https.createServer(options, app);httpsServer.listen(parseInt(config.port),function()&#123; console.log(&quot;Https server is running on: https:&#x2F;&#x2F;localhost:&quot;+config.port);&#125;); 创建https服务器时需要一个额外参数option，用来指定服务器所需证书的路径，只有证书有效，才能创建https服务。至于端口号，可以自行指定，由于网站前端运行在默认443端口，因此选择不冲突的端口即可。 创建好服务器之后，我们就可以用app实例去监听对应的请求。express框架为我们实现了路由功能，因此可以很方便的通过路径来区分各种请求。 123456789app.get(&#39;&#x2F;api&#x2F;activities&#39;,newsApi.getActivities);app.get(&#39;&#x2F;api&#x2F;activityCards&#39;,newsApi.getActivityCards);app.post(&#39;&#x2F;api&#x2F;reviewCards&#39;,newsApi.getReviewCards);function getActivities(req, res)&#123; ... ... res.send(&#39;...&#39;)&#125; 通过调用app的get和post方法，我们可以处理get和post请求，第一个参数即为路由的路径，第二个参数为一个函数闭包，用来处理对应的请求。该闭包会接受两个参数req和res，分别对应请求体和返回的内容]]></content>
      <categories>
        <category>后端学习</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
        <tag>express</tag>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git快速上手]]></title>
    <url>%2F2019%2F04%2F18%2Fgit%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%2F</url>
    <content type="text"><![CDATA[前言git作为一个先进的版本管理工具，已经被广泛应用在大量项目中。近来发现了一个非常不错的git学习网站，虽然比较基础，但是可视化的界面能够帮助新人快速理解git每项指令的功能，同时也可以一定程度上的查漏补缺。网站地址：https://learngitbranching.js.org/而本文也记录了一些常用的git指令和使用技巧 常用git指令新建仓库在当前目录初始化一个git仓库git init新建一个目录，初始化一个git仓库git init [projectName]用于从远程仓库进行克隆，一般可以选择通过https或者ssh方式git clone [url] 配置对于刚安装git的新人，一般需要配置邮箱和用户名，建议使用全局方式配置git conifg [--global] user.name &quot;[username]&quot;git conifg [--global] user.email &quot;[email]&quot;可以查看当前的git配置git config --list可以直接编辑git配置文件，之前通过命令行配置的在此也可以看到git config -e [--global] 增加、删除文件这里需要简单介绍一下git中工作区和暂存区的概念 工作区可以简单理解为你在当前仓库的种种改动，git可以检测到但是并未将之准备为下次提交的内容。需要用户将之添加到暂存区。 暂存区可以简单理解为，下次执行提交中会被提交上去的文件。 整个工作流为： 你修改了某个文件 -&gt; 该文件变为工作区文件 -&gt; 你添加该文件进入暂存区 -&gt; 提交暂存区文件，该文件被提交 添加指定文件到暂存区git add [file1] [file2] ...添加指定目录到暂存区（包含该目录下所有文件）git add [dir]添加当前目录下所有文件到暂存区git add .删除工作区文件，并将“删除”这个操作放入暂存区git rm [file1] [file2] ...停止追踪文件，但是该文件会保留在工作区，类似gitignore的作用git rm --cached [file]改名文件，并将“改名”这个操作放入暂存区git mv [origin-name] [target-name] 代码提交把暂存区内容提交到仓库， 最常用的提交指令git commit -m &quot;message&quot;提交暂存区中的指定文件到仓库git commit [file1] [file2] ... -m &quot;message&quot;直接将工作区自从上次commit之后的变化，提交到仓库（跳过暂存区）git commit -a使用一次新的commit，替代上一次提交,常用于简单修复如果代码没有任何新变化，则用来改写上一次commit的提交信息git commit --amend -m [message] 分支操作git中的分支是一个非常强大的功能，新建、删除、切换分支速度极快，可以多多使用 列出所有本地分支git branch列出所有远程分支git branch -r列出所有本地和远程分支git branch -a新建一个分支，并且留在当前分支git branch [branch-name]新建一个分支，并切换到新的分支上git checkout -b [branch-name]从某一个commit记录为起点，新建一个分支；其中commit中填入commit的hash或者tag（如果有标签）（下同）git branch [branch-name] [commit]新建一个分支，并于远程的一个分支建立追踪关系git branch --track [branch-name] [remote-branch]切换分支git checkout [branch-name]合并指定分支到当前分支git merge [branch-name]合并指定分支到当前分支，并生成线性的记录git rebase [branch-name]交互式的rebasegit rebase [branch] -i选择某一次提交（任意分支上的），合并到当前分支git cherry-pick [commit]删除分支git branch -d [branch-name]删除远程分支git branch -dr [origin/branch]git push origin --delete [branch-name] 标签标签可以用来给某一次提交添加一个可以追踪的标记，该标记不受分支影响，不会变化，可以在任何情况下被追踪。对于某一次重大提交，常常可以用标签予以标记（如某一次版本发布） 列出所有taggit tag在当前的commit上新建一个标签git tag [tag-name]给指定的commit上新建一个标签git tag [tag-name] [commit]删除本地的一个标签git tag -d [tag-name]删除远程的一个标签git push origin :refs/tags/[tag-name]查看某个标签对应的提交信息git show [tag-name]提交指定tag, remote指远程仓库的名字，一般为origingit push [remote] [tag]提交所有taggit push [remote] --tags以某个标签指定的commit为基点，新建一个分支git branch [branch-name] [tag-name] 查看信息显示有变更的文件git status显示当前分支的版本历史git log显示commit历史，以及每次commit发生变化的文件git log --stat显示指定文件的每一次改动git log -p [file]显示指定文件是什么时间被什么人修改的git blame [file]显示暂存区与工作区的差异git diff显示暂存区与上一次commit之间的差异 （可指定文件）git diff --cached [file]显示工作区与当前分支最新commit之间的差异git diff HEAD显示你今天写了多少行代码git diff --shortstat &quot;@{0 day ago}&quot;显示当前分支最近的几次提交记录（常用来进行恢复）git reflog 远程同步下载远程仓库的所有变动git fetch [remote]显示所有远程仓库git remote -v显示某个远程仓库的信息git remote show [remote]新增一个远程仓库，并命名git remote add [name] [url]拉取远程仓库的变化，并与本地分支合并git pull [remote] [branch]上传本地分支到远程仓库git push [remote] [branch]强行推送当前分支到远程仓库，即使有冲突git push [remote] --force推送所有分支到远程仓库git push [remote] --all 撤销恢复暂存区的指定文件到工作区git checkout [file]恢复某个commit的指定文件到暂存区与工作区git checkout [commit] [file]恢复暂存区的所有文件到工作区git checkout .重置暂存区的指定文件，与上一次commit保持一致，但工作区不变git reset [file]重置工作区与暂存区，与上一次commit保持一致git reset --hard重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变git reset [commit]重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致git reset --hard [commit]新建一个commit，用来撤销指定commit后者的所有变化都将被前者抵消，并且应用到当前分支常用来对远程仓库进行恢复git revert [commit]暂时将未提交的变化移除，稍后再移入git stashgit stash pop 关于git reset指令，其实有 –soft –hard –mixed三种参数，默认为 –mixed参数。具体详细用法可以参考这篇文章 git reset详解 HEAD移动HEAD在git中是一个非常重要的概念，因此在这里把这部分单独列出来。HEAD是git中用来标记当前位置的一个指针。形象的说法就是：你现在在哪，HEAD就指向哪，因为HEAD，git才知道你在哪。 一般情况下，HEAD指向当前分支（上最近的提交），但是在有些时候，我们可以让HEAD指向某一次具体的提交，这也叫做分离HEAD。比如创建分支时，如果不指定commit，那么会在当前HEAD的位置创建分支。 移动HEAD的方法是使用checkout指令，指定一个commid的hash值进行绝对定位git checkout [commit-id]我们也可以使用相对定位，以当前HEAD或分支名等可以追踪位置的标记为基准。 ^代表当前位置的前一个提交git checkout HEAD^git checkout master^我们也可以用 [number] 来一次移动多次提交`git checkout HEAD3git checkout master~5` 关于HEAD的更多用法可以进一步去搜集资料 后记以上仅仅为git 入门常用的一些指令，熟练之后可以应对一般git的使用场景。在这里依然十分推荐https://learngitbranching.js.org/进行实际操作一次，相信对git的使用有很大帮助。]]></content>
      <categories>
        <category>工具学习</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>版本控制</tag>
        <tag>常用指令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用Hexo和Github pages快速搭建个人博客]]></title>
    <url>%2F2019%2F04%2F09%2F%E7%94%A8Hexo%E5%92%8CGithub%20pages%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[为什么要写博客一直以来都有想写博客的想法，但一方面又觉得自己没有什么技术积累，言之无物，另一方面又担心没有毅力能够坚持下去。终于还是决定先行动起来，即便是记录下日常学习的心得，踩过的坑，也或许对自己对他人有些微帮助 于是今天动手用hexo简单搭建了这样一个静态博客，搭建的过程也并不复杂，感兴趣的朋友可以参照下面步骤搭建一个自己的静态博客 开始搭建准备工作 首先hexo是基于Node.js实现的，因此我们想要用hexo搭建个人主页，首先要安装Node.js 对于windows用户，建议去官网下载安装包，安装时选择 add to path， 添加环境变量 对于mac用户 可以选择使用nvm进行安装，优点在于可以方便的控制node版本（对于搭建个人博客意义不大）$ curl https://raw.github.com/creationix/nvm/v0.33.11/install.sh | sh安装好nvm后执行nvm install stable安装最新稳定版node 安装好node后，为了将其发布在Github pages上，我们还需要安装git 对于windows用户，去官网下载 git，为了方便使用命令行，建议安装git bash 对于mac用户，可以用homebrew进行安装brew install git 安装hexo准备工作完成后，我们就可以安装Hexo了npm install -g hexo-cli-g 参数指定以全局方式安装 安装好hexo后，便可以在命令行使用hexo指令 123hexo init &lt;folder&gt;cd &lt;folder&gt;npm install 其中folder为你想创建的文件夹路径，如果不指定folder，则默认会在当前文件夹创建（要求当前文件夹为空） 新建完成后，文件夹目录结构如下 12345678.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes _config.yml为全局配置文件，可以配置网站的基础信息 scaffolds文件夹存放页面的模版信息 source文件夹中的_posts文件夹用来存放我们的博文 themes文件夹存放页面所使用的主题 配置网站到了这里，我们的网站已经初步成型了，为了看到我们网站的具体样子，我们可以执行hexo server在本地运行一个服务，默认4000端口，信息如下 12INFO Start processingINFO Hexo is running at http:&#x2F;&#x2F;localhost:4000 . Press Ctrl+C to stop. 看到这样的提示，代表已经成功运行了，打开浏览器输入 localhost:4000 即可看到我们的页面 但是此时的网站没有名称，作者等一系列信息，需要我们手动配置 打开根目录下的_config.yml 如下 123456789101112# Hexo Configuration## Docs: https:&#x2F;&#x2F;hexo.io&#x2F;docs&#x2F;configuration.html## Source: https:&#x2F;&#x2F;github.com&#x2F;hexojs&#x2F;hexo&#x2F;# Sitetitle: subtitle:description:keywords:author: language: zh-Hanstimezone: 可以修改各个字段的值，如标题、作者、语言等等。可以给博客起一个喜欢的名字，并落上自己的署名 发布文章 博客配置好后，我们便可以开始书写文章了，用hexo创建一篇新文章也很简单 hexo new [layout] &lt;title&gt;layout不指定的话默认试用post的布局，默认布局可以在_config.yml中修改创建好文章后，我们就可以在source/_posts文件夹下找到并编写了，书写博文使用markdown 文章写好后，我们需要把markdown文件转换成静态的html文件以便显示在网页上，hexo为我们提供了一个简单的指令hexo generate可以简写为hexo g 在生成好文章后，刷新我们本地打开的博客网站(localhost:4000)，可以看到我们的文章已经可以显示出来啦 部署网站至此我们的博客基本功能已经实现了，但是所有的操作都只能通过本地运行的服务进行查看。为了把博客放到互联网上供所有人浏览，我们还需要将我们的博客部署到服务器上。 一个令人兴奋的消息是，github为我们提供了这样一个静态网站托管的服务，并且完全免费！我们所需要做的，仅仅是拥有一个github账号，并且创建一个用于维护github page的仓库 首先在github上创建一个仓库，仓库名称为 yourName.github.io ，yourName需要替换成你的github昵称 如果想要通过ssh验证，需要先在本机生成ssh密钥，将公钥添加到github账户上 之后需要配置本地博客网站的部署配置，依然是在_config.yml中，在文件最下方找到deploy字段如下12deploy: type: 在type字段中填写 git之后在下一行新增一个字段 repo，填入你刚刚创建的git仓库地址，应该是如下形式123deploy: type: git repo: https:&#x2F;&#x2F;github.com&#x2F;xxxx&#x2F;xxx.github.io.git repo字段根据选择的不同协议，可以选择https或者ssh认证 一切都配置完毕后，我们就可以将网站部署到github page上去了！hexo deploy可以简写为 hexo d首次部署需要进行身份验证，如果采用https协议，需要输入github账号密码。如果采用ssh协议则不需要。 如果没有提示什么错误，稍等片刻，我们在浏览器输入与刚刚创建好的仓库的同名域名 xxx.github.io 即可以看到我们创建好的个人网站了！ 个性化域名如果想要为自己的网站设置一个个性化的域名，那么我们需要向域名供应商购买一个域名并且配置相应的dns服务，更多内容可以自行查阅，本文不再过多阐述。 相关阅读hexo官方文档github pages官方指南markdown语法简介]]></content>
      <categories>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>node</tag>
        <tag>指南</tag>
      </tags>
  </entry>
</search>
